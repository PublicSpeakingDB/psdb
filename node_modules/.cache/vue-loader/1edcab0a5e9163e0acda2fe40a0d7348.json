{"remainingRequest":"/Users/aletheia/Desktop/psdb/node_modules/vue-loader/lib/index.js??vue-loader-options!/Users/aletheia/Desktop/psdb/src/components/PublicSpeakingDashboard.vue?vue&type=style&index=0&id=192f5ebb&scoped=true&lang=css&","dependencies":[{"path":"/Users/aletheia/Desktop/psdb/src/components/PublicSpeakingDashboard.vue","mtime":1700846278645},{"path":"/Users/aletheia/Desktop/psdb/node_modules/css-loader/dist/cjs.js","mtime":1700709052277},{"path":"/Users/aletheia/Desktop/psdb/node_modules/vue-loader/lib/loaders/stylePostLoader.js","mtime":1700709120020},{"path":"/Users/aletheia/Desktop/psdb/node_modules/postcss-loader/src/index.js","mtime":1700709091453},{"path":"/Users/aletheia/Desktop/psdb/node_modules/cache-loader/dist/cjs.js","mtime":1700709033581},{"path":"/Users/aletheia/Desktop/psdb/node_modules/vue-loader/lib/index.js","mtime":1700709119986}],"contextDependencies":[],"result":[{"type":"Buffer","data":"base64:
@import url("https://fonts.cdnfonts.com/css/lcd");
#textEmotion,
#faceEmotion,
#voiceEmotion,
#wpm {
  display: inline-block;
}
div {
  background-color: none;
  color: #71c68b;
}
.chartWindow {
  position: relative;
  display: inline-block;
  width: 80%;
}
.optionsButton {
  height: 50px;
  width: 75px;
  padding: 12px;
  font-size: 10px;
  margin: 5px;
  border: none;
  font-weight: bold;
  color: black;
  font-family: Arial, sans-serif;
}

.title {
  color: white;
}

#messageTwo {
  color: #f48d79;
  font-size: 25px;
}

#feedback {
  color: #ffea66;
  font-size: 25px;
  text-align: left;
  background-color: #6b206a;
  padding: 50px;
  white-space: pre-wrap;
}

#messageThree {
  color: white;
  font-size: 25px;
}

#begin {
  background-color: #c300ff;
  border: none;
  height: 50px;
  width: 100px;
  font-weight: bold;
  color: black;
  font-family: Arial, sans-serif;
  font-size: 20px;
  margin-top: 40px;
  margin-bottom: -20px;
}

#begin:hover {
  background-color: #fdfd96;
}

#start {
  background-color: #cbc3e3;
  border: none;
  height: 50px;
  width: 100px;
  font-weight: bold;
  color: black;
  font-family: Arial, sans-serif;
  font-size: 20px;
  margin: 10px;
}

#start:hover {
  background-color: lightgreen;
}

#stop {
  background-color: #cbc3e3;
  border: none;
  height: 50px;
  width: 100px;
  font-weight: bold;
  color: black;
  font-family: Arial, sans-serif;
  font-size: 20px;
  margin: 10px;
}

#stop:hover {
  background-color: #ff726f;
}

#reset {
  background-color: #cbc3e3;
  border: none;
  height: 50px;
  width: 100px;
  font-weight: bold;
  color: black;
  font-family: Arial, sans-serif;
  font-size: 20px;
  margin: 10px;
}

#reset:hover {
  background-color: lightyellow;
}

#pdf {
  background-color: #c300ff;
  border: none;
  height: 50px;
  width: 100px;
  font-weight: bold;
  color: black;
  font-family: Arial, sans-serif;
  font-size: 20px;
  margin: 10px;
}

#pdf:hover {
  background-color: #00ffc3;
}

#next {
  background-color: #7766c6;
  border: none;
  height: 50px;
  width: 100px;
  font-weight: bold;
  color: black;
  font-family: Arial, sans-serif;
  font-size: 20px;
  margin-top: 40px;
  margin-bottom: -20px;
}

#next:hover {
  background-color: #ffc300;
}

#output {
  margin: auto;
  color: #f48d79;
  background-color: #222831;
  width: 80%;
  text-align: left;
  overflow: auto;
  height: 170px;
  font-size: 25px;
  margin-top: 0px;
  margin-bottom: 0px;
}

#wpmChart {
  overflow: auto;
  width: 80%;
  display: inline-block;
  margin-top: 3px;
  margin-bottom: 0px;
}

#readabilityChart {
  overflow: auto;
  width: 80%;
  display: inline-block;
  margin-top: 3px;
  margin-bottom: 0px;
}

#volumeChart {
  overflow: auto;
  width: 80%;
  display: inline-block;
  margin-top: -3px;
}

#textEmotionChart {
  overflow: auto;
  width: 80%;
  display: inline-block;
  margin-top: -3px;
}

#faceEmotionChart {
  overflow: auto;
  width: 80%;
  display: inline-block;
  margin-top: -3px;
}

#rawData {
  display: none;
  margin: auto;
  color: lawngreen;
  background-color: #222831;
  width: 80%;
  text-align: left;
  overflow: scroll;
  height: 100px;
  font-size: 25px;
  margin: 0px;
}

#dataHideButton {
  margin: auto;
  color: #222831;
  background-color: #222831;
  width: 40%;
  text-align: center;
  height: 30px;
  font-size: 10px;
  margin: 0px;
  border: none;
}

#dataShowButton {
  margin: auto;
  color: #222831;
  background-color: #222831;
  width: 40%;
  text-align: center;
  height: 30px;
  font-size: 10px;
  margin: 0px;
  border: none;
}

h1 {
  font-size: 50px;
}
h3 {
  margin: 40px 0 0;
}
ul {
  list-style-type: none;
  padding: 0px;
}
li {
  display: inline-block;
  margin: 0 10px;
}
a {
  color: #42b983;
}

#talking {
  height: 100px;
  margin-bottom: -20px;
  -webkit-filter: invert(1);
  filter: invert(1);
}

#timer {
  background: #222831;
  color: white;
  font-size: 50px;
  font-family: "LCD", sans-serif;
  height: 100px;
  width: 80%;
  border: none;
  font-weight: bold;
  text-align: center;
  margin-bottom: 0px;
}

#timeHolder {
  background-color: #123b52;
  color: white;
  display: none;
  margin-bottom: 0px;
}

#speakingTime {
  background-color: #00ffc3;
  outline: none;
  scroll-behavior: smooth;
  height: 50px;
  width: 100px;
  font-weight: bold;
  color: black;
  font-family: Arial, sans-serif;
  font-size: 21px;
  margin: 10px;
  text-align: center;
  border: none;
}

#speakingTime:hover {
  background-color: #c300ff;
}

#volume-visualizer-wrapper {
  background-color: #222831;
  margin-top: 0px;
  padding: 0px;
  margin-bottom: 0px;
  width: 80%;
  display: inline-block;
  padding-bottom: 10px;
}

#volume-visualizer {
  --volume: 0%;
  position: relative;
  height: 10px;
  background-color: #222831;
  margin-top: 0px;
  margin-bottom: 0px;
  width: 100%;
  border: none;
  display: inline-block;
}

#volume-visualizer::before {
  content: "";
  position: absolute;
  top: 0;
  bottom: 0;
  left: 0;
  width: var(--volume);
  background-color: #c300ff;
  transition: width 100ms linear;
}
#container {
  height: 200px;
  margin-bottom: 0px;
  display: none;
  margin-top: -100px;
}

.video-container {
  position: relative;
  margin-top: 0px;
  background-color: #222831;
  width: 80%;
  display: inline-block;
}

canvas {
  position: absolute;
  left: 0;
  top: 0px;
}
.result-container {
  width: 100%;
  justify-content: center;
  align-items: center;
  flex-direction: column;
}
.result-container > div {
  font-size: 1.3rem;
  padding: 0.5rem;
  margin: 5px 0;
  color: white;
  text-transform: capitalize;
}

video {
  width: 100%;
  margin-bottom: -150px;
  margin-top: 0px;
}

#loading {
  height: 50px;
}

#loadingContainer {
  color: #fdfd96;
  margin-bottom: 150%;
  font-size: 50px;
}

#specificAndOverallFeedback {
  color: #ffbf00;
}

#initialMessage {
  font-size: 20px;
  color: #c300ff;
}

#footer {
  display: flex;
  position: float;
  bottom: 0;
  margin-top: 27%;
  height: 3rem;
  text-align: left;
}

#bugs {
  color: white;
  font-size: 12px;
}

@page {
  size: A3 landscape;
  counter-increment: page;
  margin: none;
}
"},{"version":3,"sources":["PublicSpeakingDashboard.vue"],"names":[],"mappings":";AAshDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA","file":"PublicSpeakingDashboard.vue","sourceRoot":"src/components","sourcesContent":["<template>\n  <div id=\"body\" class=\"dashboard\">\n    <p v-if=\"!loading\" id=\"loadingContainer\">\n      Initializing <br /><img\n        id=\"loading\"\n        src=\"https://media.giphy.com/media/Ky5F5Rhn1WRVZmvE5W/giphy.gif\"\n      /><br /><span id=\"initialMessage\"\n        >(Make sure your webcam is facing you.)</span\n      >\n    </p>\n    <h1 v-if=\"showProcess\" id=\"mainTitle\">\n      <img\n        id=\"talking\"\n        alt=\"image of voice waves leaving someone's mouth. Attribution: Speak Icon, by Voysla, 'https://www.flaticon.com/free-icons/speak'\"\n        src=\"talking.png\"\n      />\n      {{ msg }}\n    </h1>\n    <p v-if=\"showProcess\" id=\"messageTwo\">\n      {{ msg2 }}\n    </p>\n    <p v-if=\"showProcess\" id=\"messageThree\">\n      {{ msg3 }}\n    </p>\n    <span id=\"timeHolder\">Time: </span>\n    <!--<span><button  v-bind:style=\"{ backgroundColor: WPMColor}\" v-if=\"!show\" v-on:click=\"selectWPM\" class=\"optionsButton\" id=\"optionWPM\"> Words Per Minute</button><button v-bind:style=\"{ backgroundColor: textEmotionColor}\" v-if=\"!show\" v-on:click=\"selectTextEmotion\" class=\"optionsButton\" id=\"optionEmotionsText\"> Emotions in Text</button></span>\n\t\t<span><button v-bind:style=\"{ backgroundColor: voiceEmotionColor}\" v-if=\"!show\" v-on:click=\"selectVoiceEmotion\" class=\"optionsButton\" id=\"optionEmotionVoice\"> Emotions in Voice</button><button v-bind:style=\"{ backgroundColor: faceEmotionColor}\" v-if=\"!show\" v-on:click=\"selectFaceEmotion\" class=\"optionsButton\" id=\"optionEmotionsFace\"> Emotions in Face</button></span><br>-->\n    <span\n      ><span v-if=\"!show3\" id=\"dropdownWrapper\">\n        <label for=\"speakingTime\" alt=\"Choose Desired Speech Length:\"></label>\n        <select name=\"speakingTime\" id=\"speakingTime\">\n          <option value=\"nope\" selected>\n            Choose Target Speaking Time  -  (Gives 30 and 15 Sec Warnings Before\n            Selected Time)\n          </option>\n          <option value=\"60000\">1 Min</option>\n          <option value=\"180000\">3 Min</option>\n          <option value=\"300000\">5 Min</option>\n          <option value=\"600000\">10 Min</option>\n          <option value=\"900000\">15 Min</option>\n          <option value=\"1200000\">20 Min</option>\n          <option value=\"1500000\">25 Min</option>\n          <option value=\"1800000\">30 Min</option>\n          <option value=\"2700000\">45 Min</option>\n          <option value=\"3600000\">60 Min</option>\n        </select>\n      </span>\n      <button\n        id=\"begin\"\n        v-if=\"showBegin\"\n        v-on:click=\"\n          begin();\n          selectWPM();\n          selectTextEmotion();\n          selectVoiceEmotion();\n          selectFaceEmotion();\n        \"\n      >\n        Begin</button\n      ><button id=\"start\" v-if=\"!showStart\" v-on:click=\"begin3\">\n        Start</button\n      ><button id=\"stop\" v-if=\"!showStop\" v-on:click=\"stopVoiceControl\">\n        Stop</button\n      ><button id=\"reset\" v-if=\"!show3\" v-on:click=\"reset\">Reset</button\n      ><button id=\"pdf\" v-if=\"!show5\" v-on:click=\"pdfResults\">\n        Save\n      </button></span\n    >\n    <!--<br><button id=\"next\" v-if=\"!show\" v-on:click=\"next\">Next</button>--><br />\n    <span id=\"rawData\"></span>\n    <button v-if=\"!showTime\" class=\"title\" id=\"timer\">{{ time }}</button>\n    <span id=\"container\"\n      ><div id=\"video-container\" class=\"video-container\">\n        <video id=\"video\" autoplay width=\"150\" height=\"150\"></video></div\n    ></span>\n    <span v-if=\"!show3\" id=\"volume-visualizer-wrapper\"\n      ><button id=\"volume-visualizer\"></button\n    ></span>\n    <ul v-if=\"!show3\" id=\"output\"></ul>\n    <span\n      ><button v-if=\"!show3\" id=\"dataShowButton\" v-on:click=\"unhideData\">\n        View Raw Data</button\n      ><button v-if=\"!show3\" id=\"dataHideButton\" v-on:click=\"hideData\">\n        Hide Raw Data\n      </button></span\n    >\n\n    <!--FEEDBACK SECTION-->\n\n    <!--WPM-->\n    <span v-if=\"!showWPM\" id=\"wpmChart\"></span>\n    <span v-if=\"!showVolume\" id=\"volumeChart\"></span>\n    <span v-if=\"!showFaceEmotion\" id=\"faceEmotionChart\"></span>\n    <span v-if=\"!showTextEmotion\" id=\"readabilityChart\"></span>\n    <h1 v-if=\"!showFeedback\" id=\"specificAndOverallFeedback\">\n      Specific Feedback\n    </h1>\n    <p v-if=\"!showFeedback\" id=\"feedback\">{{ feedback }}</p>\n    <h1 v-if=\"!showFeedback2\" id=\"specificAndOverallFeedback\">\n      Overall Feedback\n    </h1>\n    <p v-if=\"!showFeedback2\" id=\"feedback\">{{ feedback2 }}</p>\n    <!-- \n\t\t<span v-if=\"!showTextEmotion\" id=\"textEmotionChart\"></span>\n -->\n\n    <footer id=\"footer\">\n      <section id=\"version\">\n        Version 0.1 (Beta)<br />\n        <div id=\"bugs\">\n          <section>\n            If you find a bug please report it here:\n            <a\n              href=\"https://rowan.co1.qualtrics.com/jfe/form/SV_8AhIsft05UgIUqW\"\n              >Bug/Error Report Form</a\n            >\n          </section>\n          <br />\n          Known Bugs and Limitations: <br />\n          <section>\n            - Current version of app works only Google Chrome on desktop\n          </section>\n          <section>\n            - User needs to speak for at least 20 seconds before meaningful\n            results are produced.\n          </section>\n        </div>\n      </section>\n    </footer>\n    <!--<p v-if=\"!showWPM\" id=\"wpm\">{{ wpm }} <br><b>Overall Average Words Per Minute</b></p><br>-->\n  </div>\n</template>\n\n<script>\n//import paralleldots from 'paralleldots'\nimport * as rs from \"text-readability\";\nimport Plotly from \"plotly.js-dist\";\nimport * as faceapi from \"face-api.js\";\nimport dotenv from \"dotenv\";\nimport axios from \"axios\";\ndotenv.config();\nexport default {\n  name: \"publicSpeakingDashboard\",\n  props: {},\n  data() {\n    return {\n      msg: \"Public Speaking Dashboard\",\n      msg2: \"An AI-powered tool to help you hone your public speaking skills.\",\n      msg3: \"\",\n      wordsSpoken: \"START\",\n      output: \"Recognized Text\",\n      workingOutput: \"\",\n      workingTime: 0,\n      grabTimeInterval: \"\",\n      registerWPMInterval: \"\",\n      getEmotionStatsInterval: \"\",\n      summarizeDataInterval: \"\",\n      voiceInterval: \"\",\n      deepGramTimeOut: \"\",  \n      initialTime: 0,\n      time: \"00:00\",\n      timeElapsed: 0,\n      timeDifference: 0,\n      wordCount: 0,\n      totalWords: 0,\n      wordCountDividedByTime: 0,\n      stop: false,\n      wpm: 0,\n      anger: 0,\n      fear: 0,\n      excitement: 0,\n      boredom: 0,\n      sadness: 0,\n      happiness: 0,\n      readability: 0,\n      show: true,\n      show2: true,\n      show3: true,\n      showProcess: true,\n      showBegin: true,\n      showStop: true,\n      showStart: true,\n      loading: true,\n      show4: true,\n      show5: true,\n      showWPM: true,\n      showTextEmotion: true,\n      showTime: true,\n      showData: true,\n      WPMSelected: false,\n      WPMColor: \"#CBC3E3\",\n      textEmotionSelected: false,\n      textEmotionColor: \"#CBC3E3\",\n      showVoiceEmotion: true,\n      voiceEmotionSelected: false,\n      voiceEmotionColor: \"#CBC3E3\",\n      showFaceEmotion: true,\n      faceEmotionSelected: false,\n      faceEmotionColor: \"#CBC3E3\",\n      textEmotionData: \"\",\n      overallDataObject: \"\",\n      currentDataObject: \"\",\n      dataNamer: 0,\n      time1: true,\n      time2: false,\n      placeHolderForTimeCheck: 0,\n      volumeCallback: null,\n      volumeInterval: null,\n      volumeValue: 0,\n      volumeNumber: 0,\n      showVolume: true,\n      faceEmotionState: \"\",\n      analyzeFaceInterval: \"\",\n      renderDataInterval: \"\",\n      //analyzingFace: true,\n      faceAngry: 0,\n      faceDisgusted: 0,\n      faceFearful: 0,\n      faceHappy: 0,\n      faceNeutral: 0,\n      faceSad: 0,\n      faceSurprised: 0,\n      continuous: true,\n      speechAgain: false,\n      API: process.env.VUE_APP_ROOT_API2,\n      API2: process.env.VUE_APP_ROOT_API3,\n      feedback: \"\",\n      feedback2: \"\",\n      showFeedback: true,\n      showFeedback2: true,\n      dataSummary: \"\",\n      referenceTime: \"\",\n      firstSummary: true,\n      dataSample: \"\",\n      tickerNumber: 0,\n      cancelCall: true,\n      android: false, \n      mediaRecorder: null,\n      socket: null,\n      transcripts: [], \n      voiceInstance: null\n    };\n  },\n\ncreated() {\n\n\tvar isAndroid = /(android)/i.test(navigator.userAgent);\n\tif (isAndroid) {\n\t\tthis.android = true\n\t\tconsole.log(\"using alternate speech recognition\")\n\t}\n\telse {\n\t\tif (\"SpeechRecognition\" in window || \"webkitSpeechRecognition\" in window) {\n\t\t\tconsole.log(\"Landing page loaded\");\n\t\t\tconsole.log(\"Speech recognition supported\");\n\t\t} else {\n\t\t\tconsole.log(\"Landing page loaded\");\n\t\t\tconsole.log(\"Speech recognition not supported.\");\n\t\t\tthis.msg2 =\n\t\t\t\"Public Speaking Dashboard is not supported by this browser and/or device. Currently, Public Speaking Dashboard only works on desktop and in the Chrome browser.\";\n\t\t\tthis.showBegin = false;\n\t\t}\n\t}\n  },\n\n  methods: {\n  \n  begin3: function () {\n  \n\tthis.showStart = true\n\tthis.showStop = false\n  \n\tif (this.android == true){\n\t\tthis.stop = false;\n\t\tthis.deepGramTimeOut = window.setTimeout(this.stopVoiceControl, 15000);\n\t\tthis.begin2()\n\t}\n\tif (this.android == false) {\n\t\tthis.stop = false;\n\t\tthis.initiateVoiceControl()\n\t}\n  \n  },\n  \nbegin2: async function () {\nif (this.stop == false) {\n  try {\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n    if (!MediaRecorder.isTypeSupported('audio/webm')) {\n      alert('Unsupported browser');\n      return;\n    }\n    this.mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });\n\n    const DG_URL = 'wss://api.deepgram.com/v1/listen?language=en';\n    const DG_KEY = this.API2;\n    this.socket = new WebSocket(DG_URL, ['token', DG_KEY]);\n    this.socket.onopen = () => this.startStreaming();\n    this.socket.onmessage = (message) => this.handleResponse(message);\n    \n    if (\n        this.textEmotionSelected == true ||\n        this.WPMSelected == true ||\n        this.voiceEmotionSelected == true ||\n        this.faceEmotionSelected == true\n      ) {\n        this.msg3 = \"\";\n        if (this.stop == false) {\n          this.cancelCall = false;\n          this.showTime = false;\n          this.initialTime = Date.now();\n          this.grabTimeInterval = window.setInterval(this.grabTime, 1000);\n          this.renderDataInterval = window.setInterval(this.renderData, 1000);\n          this.summarizeDataInterval = window.setInterval(this.summarizeData, 15000);\n\n          this.startVolumeMeter();\n          document.getElementById(\"container\").style.display = \"inline\";\n          this.showStop = false;\n          this.visualizeData();\n          console.log(\"app started\");\n          this.show5 = true;\n\t\t\tthis.stop = true;\n          // if (this.analyzingFace == false){this.analyzeFace()}\n        }\n\n      } else {\n        this.msg2 =\n          \"No input data selected. Try selecting words per minute or another parameter.\";\n      }\n  } catch (error) {\n    alert(error);\n  }\n  }\n},\n\nstartStreaming: function () {\n  this.mediaRecorder.addEventListener('dataavailable', (event) => {\n    if (event.data.size > 0 && this.socket.readyState == 1) {\n      this.socket.send(event.data);\n    }\n  });\n\n  this.mediaRecorder.start(50); // Start recording in chunks of 250ms\n},\n\nhandleResponse: function (message) {\n  const received = JSON.parse(message.data);\n  const alternatives = received.channel && received.channel.alternatives;\n  if (alternatives && alternatives.length > 0) {\n    const transcript = alternatives[0].transcript;\n    if (transcript) {\n      this.transcripts.push(transcript);\n      console.log(\"deepgram \" + transcript);\n      window.clearTimeout(this.deepGramTimeOut);\n      this.deepGramTimeOut = window.setTimeout(this.stopVoiceControl, 15000);\n      \n      if (this.workingTime) {\n              this.workingOutput = transcript;\n              var node = document.createElement(\"li\");\n              node.appendChild(document.createTextNode(\" \" + this.workingTime + \": \" + this.workingOutput));\n              document.querySelector(\"ul\").appendChild(node);\n              var elem = document.getElementById(\"output\");\n              elem.scrollTop = elem.scrollHeight;\n              \n              this.wordsSpoken = transcript;\n              this.output = this.output += this.wordsSpoken\n              this.wordCount = this.countWords(this.output);\n              this.totalWords = this.wordCount;\n      \n      }\n      \n    }\n  }\n},\n\n  \n    begin: function () {\n      //initiate speech recognition and ask for microphone permission\n      this.analyzeFace();\n      window.SpeechRecognition =\n        window.webkitSpeechRecognition || window.SpeechRecognition;\n      let recognition = new window.SpeechRecognition();\n      recognition.start();\n      this.show = false;\n      this.showStart = false;\n      this.msg2 = \"\";\n      this.msg3 =\n        \"Choose a desired speech length. Click start. Then, click stop when finished.\";\n      console.log(\"Dashboard page loaded\");\n    },\n\n    startVolumeMeter: function () {\n      (async () => {\n        const volumeVisualizer = document.getElementById(\"volume-visualizer\");\n        // Initialize\n        try {\n          const audioStream = await navigator.mediaDevices.getUserMedia({\n            audio: {\n              echoCancellation: true,\n            },\n          });\n\n          const audioContext = new AudioContext();\n          const audioSource = audioContext.createMediaStreamSource(audioStream);\n          const analyser = audioContext.createAnalyser();\n          analyser.fftSize = 512;\n          analyser.minDecibels = -127;\n          analyser.maxDecibels = 0;\n          analyser.smoothingTimeConstant = 0.4;\n          audioSource.connect(analyser);\n          const volumes = new Uint8Array(analyser.frequencyBinCount);\n          this.volumeCallback = () => {\n            analyser.getByteFrequencyData(volumes);\n            let volumeSum = 0;\n            for (const volume of volumes) volumeSum += volume;\n            const averageVolume = volumeSum / volumes.length;\n            // Value range: 127 = analyser.maxDecibels - analyser.minDecibels;\n            volumeVisualizer.style.setProperty(\n              \"--volume\",\n              (averageVolume * 100) / 127 + \"%\"\n            );\n            this.volumeNumber = averageVolume;\n            this.showVolume = false;\n          };\n        } catch (e) {\n          console.error(\n            \"Failed to initialize volume visualizer, simulating instead...\",\n            e\n          );\n          let lastVolume = 50;\n          this.volumeCallback = () => {\n            const volume = Math.min(\n              Math.max(Math.random() * 100, 0.8 * lastVolume),\n              1.2 * lastVolume\n            );\n            lastVolume = volume;\n            volumeVisualizer.style.setProperty(\"--volume\", volume + \"%\");\n          };\n        }\n        // Use\n\n        if (this.volumeCallback !== null && this.volumeInterval === null)\n          this.volumeInterval = setInterval(this.volumeCallback, 100);\n      })();\n    },\n\n    setVolume: function () {\n      this.volumeValue = Math.round(this.volumeNumber);\n    },\n\n    selectWPM: function () {\n      if (this.WPMSelected == false) {\n        this.msg2 = \"\";\n        this.WPMSelected = true;\n        this.WPMColor = \"#f48d79\";\n        if (this.WPMSelected == true) {\n          this.showWPM = false;\n        }\n      } else {\n        this.WPMSelected = false;\n        this.WPMColor = \"#CBC3E3\";\n        if (this.WPMSelected == false) {\n          this.showWPM = true;\n        }\n      }\n    },\n\n    selectTextEmotion: function () {\n      if (this.textEmotionSelected == false) {\n        this.msg2 = \"\";\n        this.textEmotionSelected = true;\n        this.textEmotionColor = \"#f48d79\";\n        if (this.textEmotionSelected == true) {\n          this.showTextEmotion = false;\n        }\n      } else {\n        this.textEmotionSelected = false;\n        this.textEmotionColor = \"#CBC3E3\";\n        if (this.textEmotionSelected == false) {\n          this.showTextEmotion = true;\n        }\n      }\n    },\n\n    selectVoiceEmotion: function () {\n      if (this.voiceEmotionSelected == false) {\n        this.msg2 = \"\";\n        this.voiceEmotionSelected = true;\n        this.voiceEmotionColor = \"#f48d79\";\n        if (this.voiceEmotionSelected == true) {\n          this.showVoiceEmotion = false;\n        }\n      } else {\n        this.voiceEmotionSelected = false;\n        this.voiceEmotionColor = \"#CBC3E3\";\n        if (this.voiceEmotionSelected == false) {\n          this.showVoiceEmotion = true;\n        }\n      }\n    },\n\n    selectFaceEmotion: function () {\n      if (this.faceEmotionSelected == false) {\n        this.msg2 = \"\";\n        this.faceEmotionSelected = true;\n        this.faceEmotionColor = \"#f48d79\";\n        if (this.faceEmotionSelected == true) {\n          this.showFaceEmotion = false;\n        }\n      } else {\n        this.faceEmotionSelected = false;\n        this.faceEmotionColor = \"#CBC3E3\";\n        if (this.faceEmotionSelected == false) {\n          this.showFaceEmotion = true;\n        }\n      }\n    },\n\n    initiateVoiceControl: function () {\n      //start listening for words and making a transcript of detected words\n      console.log(\"Voice this.voiceInstance initiated\");\n      window.SpeechRecognition = window.webkitSpeechRecognition; //|| window.Speechthis.voiceInstance;\n      window.SpeechGrammarList = window.webkitSpeechGrammarList; //|| window.SpeechGrammarList;\n      window.SpeechRecognitionEvent = window.webkitSpeechRecognitionEvent; //|| window.Speechthis.voiceInstanceEvent;\n\n      let finalTranscript = \"\";\n      this.voiceInstance = new window.SpeechRecognition();\n      this.voiceInstance.interimResults = true;\n      this.voiceInstance.maxAlternatives = 10;\n      this.voiceInstance.continuous = true;\n      (this.voiceInstance.onresult = (event) => {\n        let interimTranscript = \"\";\n        for (\n          let i = event.resultIndex, len = event.results.length;\n          i < len;\n          i++\n        ) {\n          let transcript = event.results[i][0].transcript;\n          if (event.results[i].isFinal) {\n            finalTranscript += transcript;\n            if (this.workingTime) {\n              this.workingOutput = transcript;\n              var node = document.createElement(\"li\");\n              node.appendChild(\n                document.createTextNode(\n                  \" \" + this.workingTime + \": \" + this.workingOutput\n                )\n              );\n              document.querySelector(\"ul\").appendChild(node);\n              var elem = document.getElementById(\"output\");\n              elem.scrollTop = elem.scrollHeight;\n              console.log(\"SpeechRecognition: \" + this.workingOutput);\n\n            }\n          } else {\n            interimTranscript += transcript;\n          }\n        }\n        this.wordsSpoken = finalTranscript;\n        this.output = this.wordsSpoken += interimTranscript;\n        this.wordCount = this.countWords(this.output);\n        this.totalWords = this.wordCount;\n      }),\n        \n\nthis.voiceInstance.addEventListener(\"end\", () => {\n\nif (this.stop == false) {\n  this.stopVoiceControl()\n  console.log(\"SpeechRecognition app stopped\")\n  }\n    console.log(\"SpeechRecognition app stopped\")\n});\n\n        this.msg3 = \"\";\n\n        if (this.stop == false) {\n        this.voiceInstance.start()\n          this.cancelCall = false;\n          this.showTime = false;\n          this.initialTime = Date.now();\n          this.grabTimeInterval = window.setInterval(this.grabTime, 1000);\n          this.renderDataInterval = window.setInterval(this.renderData, 1000);\n          this.summarizeDataInterval = window.setInterval(this.summarizeData, 15000);\n          //this.voiceInterval = window.setInterval(this.voiceInstance.start(), 25000);\n\n          this.startVolumeMeter();\n          document.getElementById(\"container\").style.display = \"inline\";\n          this.showStop = false;\n          this.visualizeData();\n          console.log(\"app started\");\n          this.show5 = true;\n\n          // if (this.analyzingFace == false){this.analyzeFace()}\n        }\n    },\n\n    analyzeFace: function () {\n      this.showProcess = false;\n      this.showBegin = false;\n      const video = document.querySelector(\"video\");\n      this.loading = false;\n      const videoContainer = document.getElementById(\"video-container\");\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(\"./models\"),\n        faceapi.nets.faceLandmark68Net.loadFromUri(\"./models\"),\n        faceapi.nets.faceRecognitionNet.loadFromUri(\"./models\"),\n        faceapi.nets.faceExpressionNet.loadFromUri(\"./models\"),\n      ]).then(startVideo);\n\n      function startVideo() {\n        var constraints = { audio: false, video: true };\n\n        navigator.mediaDevices\n          .getUserMedia(constraints)\n          .then(function (mediaStream) {\n          //ios attributes\n\t\t\tvideo.setAttribute(\"autoplay\", \"true\");\n\t\t\tvideo.setAttribute(\"playsinline\", \"true\");\n\t\t\tvideo.setAttribute(\"muted\", \"true\");\n\t\t\tvideo.setAttribute(\"loop\", \"true\");\n\t\t\t//\n            video.srcObject = mediaStream;\n            \n            //for ios?\n            video.onloadedmetadata = function() {\n            video.play()\n        }\n        //\n            \n            \n          })\n          .catch(function (err) {\n            console.log(err.name + \": \" + err.message);\n          });\n      }\n\n      video.addEventListener(\"playing\", () => {\n        console.log(\"Initializing face recognition\");\n        const canvas = faceapi.createCanvasFromMedia(video);\n        canvas.willReadFrequently = true;\n        videoContainer.appendChild(canvas);\n\n        const displaySize = { width: video.width, height: video.height };\n        faceapi.matchDimensions(canvas, displaySize);\n\n        this.analyzeFaceInterval = window.setInterval(async () => {\n          const detections = await faceapi\n            .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())\n            .withFaceLandmarks()\n            .withFaceExpressions();\n\n          const resizedDetections = faceapi.resizeResults(\n            detections,\n            displaySize\n          );\n\n          canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\n\n          const resizedResults = faceapi.resizeResults(detections, displaySize);\n          faceapi.draw.drawDetections(canvas, resizedDetections);\n\n          const minProbability = 0.01;\n          faceapi.draw.drawFaceExpressions(\n            canvas,\n            resizedResults,\n            minProbability\n          );\n\n          if (resizedDetections && Object.keys(resizedDetections).length > 0) {\n            const expressions = resizedDetections.expressions;\n            const maxValue = Math.max(...Object.values(expressions));\n            const emotion = Object.keys(expressions).filter(\n              (item) => expressions[item] === maxValue\n            );\n\n            this.faceEmotionState = '\"' + `${emotion[0]}` + '\"';\n\n            if (this.loading == false) {\n              this.loading = true;\n              this.show3 = false;\n              this.showProcess = true;\n            }\n          }\n\n          this.faceAngry = Math.round(detections.expressions.angry * 100);\n          this.faceDisgusted = Math.round(\n            detections.expressions.disgusted * 100\n          );\n          this.faceFearful = Math.round(detections.expressions.fearful * 100);\n          this.faceHappy = Math.round(detections.expressions.happy * 100);\n          this.faceNeutral = Math.round(detections.expressions.neutral * 100);\n          this.faceSad = Math.round(detections.expressions.sad * 100);\n          this.faceSurprised = Math.round(\n            detections.expressions.surprised * 100\n          );\n        }, 500);\n      });\n    },\n\n    grabTime: function () {\n      //keep  of time in both milliseconds as well as minutes and seconds\n\n      if (this.time1 == true) {\n        this.timeDifference = Date.now() - this.initialTime;\n        this.dataNamer = this.timeDifference;\n        var div = document.getElementById(\"timeHolder\");\n        div.innerHTML = this.dataNamer;\n      }\n\n      if (this.time1 == false) {\n        this.timeDifference = Date.now() - this.initialTime;\n        var middleTime = parseInt(\n          document.getElementById(\"timeHolder\").innerHTML\n        );\n        this.timeDifference = this.timeDifference + middleTime;\n        this.time2 = true;\n      }\n\n      var formatted = convertTime(this.timeDifference);\n      document.getElementById(\"timer\").innerHTML = \"\" + formatted;\n      this.workingTime = formatted;\n      console.log(formatted);\n      this.timeElapsed = this.timeDifference;\n      this.placeHolderForTimeCheck = this.timeDifference;\n      var selectedTime = document.getElementById(\"speakingTime\").value;\n      var selectedTimeFifteen = selectedTime - 15000;\n      var selectedTimeThirty = selectedTime - 30000;\n      var element = document.getElementById(\"timer\");\n      if (this.placeHolderForTimeCheck >= selectedTimeThirty) {\n        element.style.backgroundColor = \"green\";\n      }\n      if (this.placeHolderForTimeCheck >= selectedTimeFifteen) {\n        element.style.backgroundColor = \"yellow\";\n      }\n      if (this.placeHolderForTimeCheck >= selectedTime) {\n        element.style.backgroundColor = \"red\";\n      }\n\n      function convertTime(miliseconds) {\n        var totalSeconds = Math.floor(miliseconds / 1000);\n        var minutes = Math.floor(totalSeconds / 60);\n        var seconds = totalSeconds - minutes * 60;\n        if (seconds < 10) {\n          seconds = \"0\" + seconds;\n        }\n        if (minutes < 10) {\n          minutes = \"0\" + minutes;\n        }\n        return minutes + \":\" + seconds;\n      }\n    },\n\n    countWords: function (str) {\n      //count how many words are in the transcript of detected words\n      const arr = str.split(\" \");\n      return arr.filter((word) => word !== \"\").length;\n    },\n\n    registerWPM: function () {\n      //calculate number of words per minute--at one second intervals\n      this.wpm = Math.round((this.wordCount / (this.timeElapsed / 1000)) * 60);\n    },\n\n    //getEmotionStats: function () {\n    //send transcript data to be evaluated as per emotional content\n    // const pd = require('paralleldots' || paralleldots)\n    // \t\t\tpd.apiKey = \"hL7rOIhghKLZtrI6w04cFjxVvAOHQ7BiNhjMLAVnMPw\";\n    // \t\t\tpd.emotion(this.workingOutput,\"en\")\n    // \t\t\t.then((response) => {\n    // \t\t\t\tlet obj = JSON.parse(response)\n    // \t\t\t\tthis.textEmotionData = response.slice(1)\n    // \t\t\t\tthis.anger = Math.round(obj.emotion.Angry * 100)\n    // \t\t\t\tthis.fear = Math.round(obj.emotion.Fear * 100)\n    // \t\t\t\tthis.excitement = Math.round(obj.emotion.Excited * 100)\n    // \t\t\t\tthis.boredom = Math.round(obj.emotion.Bored * 100)\n    // \t\t\t\tthis.sadness = Math.round(obj.emotion.Sad * 100)\n    // \t\t\t\tthis.happiness = Math.round(obj.emotion.Happy * 100)\n    // \t\t\t})\n    // \t\t\t\t.catch((error) => {\n    // \t\t\t\tconsole.log(error);\n    // \t\t\t})\n\n    //},\n\n    getReadabilityStats: function () {\n      this.readability = rs.gunningFog(this.workingOutput);\n    },\n\n    stopVoiceControl: function () {\n      //reset speech recognition so it can stop and clear original timers\n      this.showStart = false\n      this.showStop = true\n      this.stop = true;\n      this.time1 = false;\n      if (this.time2 == true) {\n        this.dataNamer = this.timeDifference;\n        var div2 = document.getElementById(\"timeHolder\");\n        div2.innerHTML = this.dataNamer;\n      }\n      if (this.volumeInterval !== null) {\n        clearInterval(this.volumeInterval);\n        this.volumeInterval = null;\n      }\n      if (this.cancelCall == false) {\n        this.summarizeData();\n        this.visualizeData();\n        clearInterval(this.grabTimeInterval);\n        clearInterval(this.renderDataInterval);\n        clearInterval(this.summarizeDataInterval);\n        //clearInterval(this.voiceInterval);\n          this.showTime = false;\n          this.stop = true;\n          this.show5 = false;\n          this.showTime = false;\n          this.show5 = false;\n\t\t\tif (this.android == false){\n\t\t\t\tthis.voiceInstance.stop();\n\t\t\t}\n\t\t\t\n\t\t\tif (this.android == true) {\n\t\t\tthis.mediaRecorder.stop();\n\t\t\tconsole.log(\"android app stopped\");\n\t\t}\n        setTimeout(() => {\n          this.getFeedback();\n        }, 1000);\n        this.cancelCall = true;\n      }\n      \n\n      //clearInterval(this.analyzeFaceInterval)\n      //this.analyzingFace = false\n    },\n\n    reset: function () {\n      location.reload();\n    },\n\n    unhideData: function () {\n      document.getElementById(\"rawData\").style.display = \"inline-block\";\n    },\n\n    hideData: function () {\n      document.getElementById(\"rawData\").style.display = \"none\";\n    },\n\n    renderData: function () {\n      const promise1 = new Promise((resolve, reject) => {\n        this.setVolume();\n        //this.getEmotionStats()\n        this.getReadabilityStats();\n        this.registerWPM();\n        resolve(\"Data rendered!\");\n        reject(\"Data render failed\");\n      });\n\n      promise1.then(() => {\n        this.constructJSON();\n        this.visualizeData();\n        this.resetWorkingOutput();\n      });\n    },\n\n    constructJSON: function () {\n      this.currentDataObject =\n        '{\"time\":' +\n        '\"' +\n        this.workingTime +\n        '\"' +\n        \",\" +\n        '\"wpm\":' +\n        '\"' +\n        this.wpm +\n        '\"' +\n        \",\" +\n        '\"content\":' +\n        '\"' +\n        this.workingOutput +\n        '\"' +\n        \",\" +\n        '\"volume\":' +\n        this.volumeValue +\n        \",\" +\n        '\"word_complexity\":' +\n        this.readability +\n        \",\" +\n        '\"faceAnger\":' +\n        this.faceAngry +\n        \",\" +\n        '\"faceDisgust\":' +\n        this.faceDisgusted +\n        \",\" +\n        '\"faceFear\":' +\n        this.faceFearful +\n        \",\" +\n        '\"faceHappiness\":' +\n        this.faceHappy +\n        \",\" +\n        '\"faceNeutral\":' +\n        this.faceNeutral +\n        \",\" +\n        '\"faceSadness\":' +\n        this.faceSad +\n        \",\" +\n        '\"faceSurprise\":' +\n        this.faceSurprised +\n        \"},\";\n      var div = document.getElementById(\"rawData\");\n      div.innerHTML += this.currentDataObject;\n      this.overallDataObject = document.getElementById(\"rawData\").innerHTML;\n    },\n\n    summarizeData: function () {\n      var overallRawData = document.getElementById(\"rawData\").innerHTML;\n      const overallSlicedDataArray = JSON.parse(\n        \"[\" + overallRawData.slice(0, -1) + \"]\"\n      );\n      const numberOfObjects = overallSlicedDataArray.length;\n      const dataSource = JSON.stringify(overallSlicedDataArray);\n      const workingValue = numberOfObjects - 1;\n      const instance = this;\n      const actualTime = instance.workingTime;\n\n      if (instance.firstSummary == false) {\n        instance.dataSample = dataSource.substring(\n          dataSource.indexOf(instance.referenceTime)\n        );\n        instance.referenceTime = overallSlicedDataArray[workingValue].time;\n        //dataSource[numberOfObjects2 - 1].time;\n      }\n\n      if (instance.firstSummary == true) {\n        instance.dataSample = dataSource;\n        instance.referenceTime = overallSlicedDataArray[workingValue].time;\n        instance.firstSummary = false;\n      }\n\n      const client = axios.create({\n        headers: {\n          Authorization: \"Bearer \" + instance.API,\n        },\n      });\n\n      const params = {\n        model: \"gpt-3.5-turbo-instruct\",\n        prompt:\n          \"Sumarize the following data. The data represents values taken from a section of a speech. Explain to the speaker their speech dynamics while quoting the specific content that corresponds to the other included data about the section of the speech. Data: \" +\n          instance.dataSample,\n        temperature: 0,\n        max_tokens: 900,\n        top_p: 1,\n        frequency_penalty: 0,\n        presence_penalty: 0,\n      };\n\n      client\n        .post(\"https://api.openai.com/v1/completions\", params)\n        .then((result) => {\n          instance.showFeedback = false;\n          const rawResultA = result.data.choices[0].text + \" \";\n          instance.dataSummary = instance.dataSummary +=\n            \"$\" + actualTime + \" \" + rawResultA + \"\\n\\n\";\n          instance.feedback = instance.dataSummary;\n          // let div = document.getElementById(\"feedback\");\n          // let p = document.createElement(\"p\");\n          // p.innerText = instance.workingTime + \": \" + rawResultA;\n          // div.appendChild(p);\n        })\n        .catch((error) => {\n          console.log(error);\n          this.msg = error;\n        });\n    },\n\n    getFeedback: function () {\n      const instance = this;\n      console.log(\"final input\" + instance.dataSummary);\n      const client = axios.create({\n        headers: {\n          Authorization: \"Bearer \" + instance.API,\n        },\n      });\n\n      const params = {\n        model: \"gpt-3.5-turbo-instruct\",\n        prompt:\n          \"Give overall summary as well as the averages for data values from the following outputs. Each statement follows a '$' symbol, indicating a timetamp for the section of the speech that the statement corresponds to. Outputs: \" +\n          instance.dataSummary,\n        temperature: 0,\n        max_tokens: 2107,\n        top_p: 1,\n        frequency_penalty: 0,\n        presence_penalty: 0,\n      };\n\n      client\n        .post(\"https://api.openai.com/v1/completions\", params)\n        .then((result) => {\n          instance.showFeedback2 = false;\n          const rawResultA = result.data.choices[0].text;\n          instance.feedback2 = rawResultA;\n          console.log(\"final output\" + rawResultA);\n        })\n        .catch((error) => {\n          console.log(error);\n          this.msg = error;\n        });\n    },\n\n    resetWorkingOutput: function () {\n      this.workingOutput = \"\";\n    },\n\n    pdfResults: function () {\n      window.print();\n    },\n\n    visualizeData: function () {\n      var overallRawData = document.getElementById(\"rawData\").innerHTML;\n      var overallSlicedDataArray = \"[\" + overallRawData.slice(0, -1) + \"]\";\n      var data = JSON.parse(overallSlicedDataArray);\n\n      //Words Per Minute\n      if (this.showWPM == false) {\n        let wordsPerMinute = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Words Per Minute\",\n          line: {\n            color: \"#f48d79\",\n            width: 2,\n          },\n        };\n\n        data.forEach(function (val) {\n          wordsPerMinute.x.push(val[\"time\"]);\n          wordsPerMinute.y.push(val[\"wpm\"]);\n        });\n\n        var layout = {\n          paper_bgcolor: \"#222831\",\n          plot_bgcolor: \"#222831\",\n          title: {\n            text: \"Rate of Speech\",\n            font: {\n              family: \"Arial, sans-serif\",\n              size: 20,\n              color: \"#71c68b\",\n            },\n            xref: \"paper\",\n            automargin: true,\n            x: 0.5,\n            xanchor: \"center\",\n            y: 0.88,\n            yanchor: \"top\",\n          },\n          autosize: true,\n          xaxis: {\n            tickfont: {\n              size: 18,\n              color: \"#71c68b\",\n            },\n            tickcolor: \"#36454f\",\n            title: {\n              text: \"Time\",\n              font: {\n                family: \"Arial, sans-serif\",\n                size: 18,\n                color: \"#71c68b\",\n              },\n            },\n          },\n          yaxis: {\n            margin: {\n              autoexpand: true,\n            },\n            automargin: true,\n            tickfont: {\n              size: 18,\n              color: \"#71c68b\",\n            },\n            tickcolor: \"#36454f\",\n            title: {\n              text: \"Words Per Minute\",\n              font: {\n                family: \"Arial, sans-serif\",\n                size: 18,\n                color: \"#71c68b\",\n              },\n            },\n          },\n        };\n\n        var WPMChart = document.getElementById(\"wpmChart\");\n        Plotly.newPlot(WPMChart, [wordsPerMinute], layout);\n      }\n\n      //Volume\n      if (this.showVolume == false) {\n        let volume = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Volume\",\n          line: {\n            color: \"#40D0E0\",\n            width: 2,\n          },\n        };\n\n        data.forEach(function (val) {\n          volume.x.push(val[\"time\"]);\n          volume.y.push(val[\"volume\"]);\n        });\n\n        var layout3 = {\n          paper_bgcolor: \"#222831\",\n          plot_bgcolor: \"#222831\",\n          title: {\n            text: \"Voice Projection\",\n            font: {\n              family: \"Arial, sans-serif\",\n              size: 20,\n              color: \"#c300ff\",\n            },\n            xref: \"paper\",\n            automargin: true,\n            x: 0.5,\n            xanchor: \"center\",\n            y: 0.88,\n            yanchor: \"top\",\n          },\n          autosize: true,\n          xaxis: {\n            tickfont: {\n              size: 18,\n              color: \"#c300ff\",\n            },\n            tickcolor: \"#c300ff\",\n            title: {\n              text: \"Time\",\n              font: {\n                family: \"Arial, sans-serif\",\n                size: 18,\n                color: \"#c300ff\",\n              },\n            },\n          },\n          yaxis: {\n            margin: {\n              autoexpand: true,\n            },\n            automargin: true,\n            tickfont: {\n              size: 18,\n              color: \"#c300ff\",\n            },\n            tickcolor: \"#c300ff\",\n            title: {\n              text: \"Volume\",\n              font: {\n                family: \"Arial, sans-serif\",\n                size: 18,\n                color: \"#c300ff\",\n              },\n            },\n          },\n        };\n\n        var volumeChart = document.getElementById(\"volumeChart\");\n        Plotly.newPlot(volumeChart, [volume], layout3);\n      }\n\n      //Readability\n      if (this.showVolume == false) {\n        let word_complexity = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Volume\",\n          line: {\n            color: \"#40D0E0\",\n            width: 2,\n          },\n        };\n\n        data.forEach(function (val) {\n          word_complexity.x.push(val[\"time\"]);\n          word_complexity.y.push(val[\"word_complexity\"]);\n        });\n\n        var layout5 = {\n          paper_bgcolor: \"#222831\",\n          plot_bgcolor: \"#222831\",\n          title: {\n            text: \"Complexity of Words Spoken\",\n            font: {\n              family: \"Arial, sans-serif\",\n              size: 20,\n              color: \"#fdfd96\",\n            },\n            xref: \"paper\",\n            automargin: true,\n            x: 0.6,\n            xanchor: \"center\",\n            y: 0.88,\n            yanchor: \"top\",\n          },\n          autosize: true,\n          xaxis: {\n            tickfont: {\n              size: 16,\n              color: \"#fdfd96\",\n            },\n            tickcolor: \"#36454f\",\n            title: {\n              text: \"Time\",\n              font: {\n                family: \"Arial, sans-serif\",\n                size: 18,\n                color: \"#fdfd96\",\n              },\n            },\n          },\n          yaxis: {\n            margin: {\n              autoexpand: true,\n            },\n            automargin: true,\n            tickfont: {\n              size: 16,\n              color: \"#fdfd96\",\n            },\n            tickcolor: \"#fdfd96\",\n            title: {\n              text: \"Grade Level\",\n              font: {\n                family: \"Arial, sans-serif\",\n                size: 18,\n                color: \"#fdfd96\",\n              },\n            },\n          },\n        };\n\n        var readabilityChart = document.getElementById(\"readabilityChart\");\n        Plotly.newPlot(readabilityChart, [word_complexity], layout5);\n      }\n\n      //Emotions in Face\n      if (this.faceEmotionSelected == true) {\n        let Angry = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Anger\",\n          line: {\n            color: \"#ff6961\",\n            width: 2,\n          },\n        };\n\n        let Fearful = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Fear\",\n          line: {\n            color: \"#fdfd96\",\n            width: 2,\n          },\n        };\n\n        let Excited = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Surprise\",\n          line: {\n            color: \"#ffb347\",\n            width: 2,\n          },\n        };\n\n        let Bored = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Neutral\",\n          line: {\n            color: \"#cfcfc4\",\n            width: 2,\n          },\n        };\n\n        let Sad = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Sadness\",\n          line: {\n            color: \"#85A1F2\",\n            width: 2,\n          },\n        };\n\n        let Happy = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Happiness\",\n          line: {\n            color: \"#77dd77\",\n            width: 2,\n          },\n        };\n\n        let Disgusted = {\n          x: [],\n          y: [],\n          mode: \"lines\",\n          name: \"Disgust\",\n          line: {\n            color: \"##FF5733\",\n            width: 2,\n          },\n        };\n\n        data.forEach(function (val) {\n          Angry.x.push(val[\"time\"]);\n          Angry.y.push(val[\"faceAnger\"]);\n          Fearful.x.push(val[\"time\"]);\n          Fearful.y.push(val[\"faceFear\"]);\n          Excited.x.push(val[\"time\"]);\n          Excited.y.push(val[\"faceSurprise\"]);\n          Bored.x.push(val[\"time\"]);\n          Bored.y.push(val[\"faceNeutral\"]);\n          Sad.x.push(val[\"time\"]);\n          Sad.y.push(val[\"faceSadness\"]);\n          Happy.x.push(val[\"time\"]);\n          Happy.y.push(val[\"faceHappiness\"]);\n          Disgusted.x.push(val[\"time\"]);\n          Disgusted.y.push(val[\"faceDisgust\"]);\n        });\n\n        var layout4 = {\n          paper_bgcolor: \"#222831\",\n          plot_bgcolor: \"#222831\",\n          title: {\n            text: \"  Expressions in Face\",\n            font: {\n              family: \"Arial, sans-serif\",\n              size: 20,\n              color: \"#f48d79\",\n            },\n            xref: \"paper\",\n            automargin: true,\n            x: 0.6,\n            xanchor: \"center\",\n            y: 0.88,\n            yanchor: \"top\",\n          },\n          autosize: true,\n          xaxis: {\n            tickfont: {\n              size: 16,\n              color: \"#f48d79\",\n            },\n            tickcolor: \"#f48d79\",\n            title: {\n              text: \"Time\",\n              font: {\n                family: \"Arial, sans-serif\",\n                size: 18,\n                color: \"#f48d79\",\n              },\n            },\n          },\n          yaxis: {\n            margin: {\n              autoexpand: true,\n            },\n            automargin: true,\n            tickfont: {\n              size: 16,\n              color: \"#f48d79\",\n            },\n            tickcolor: \"#f48d79\",\n            title: {\n              text: \"Expressions\",\n              font: {\n                family: \"Arial, sans-serif\",\n                size: 18,\n                color: \"#f48d79\",\n              },\n            },\n          },\n        };\n\n        var FACEEMOTIONChart = document.getElementById(\"faceEmotionChart\");\n        Plotly.newPlot(\n          FACEEMOTIONChart,\n          [Angry, Fearful, Excited, Bored, Sad, Happy, Disgusted],\n          layout4\n        );\n      }\n\n      // Emotions in Text\n      // \t\t\tif (this.textEmotionSelected == true) {\n      //\n      // \t\t\t\tlet Anger = {\n      // \t\t\t\t\tx: [],\n      // \t\t\t\t\ty: [],\n      // \t\t\t\t\tmode: \"lines\",\n      // \t\t\t\t\tname: 'Anger',\n      // \t\t\t\t\tline: {\n      // \t\t\t\t\t\tcolor: '#ff6961',\n      // \t\t\t\t\t\twidth: 2\n      // \t\t\t\t\t}\n      // \t\t\t\t};\n      //\n      // \t\t\t\tlet Fear = {\n      // \t\t\t\t\tx: [],\n      // \t\t\t\t\ty: [],\n      // \t\t\t\t\tmode: \"lines\",\n      // \t\t\t\t\tname: 'Fear',\n      // \t\t\t\t\tline: {\n      // \t\t\t\t\t\tcolor: '#fdfd96',\n      // \t\t\t\t\t\twidth: 2\n      // \t\t\t\t\t}\n      // \t\t\t\t};\n      //\n      // \t\t\t\tlet Excitement = {\n      // \t\t\t\t\tx: [],\n      // \t\t\t\t\ty: [],\n      // \t\t\t\t\tmode: \"lines\",\n      // \t\t\t\t\tname: 'Excitement',\n      // \t\t\t\t\tline: {\n      // \t\t\t\t\t\tcolor: '#ffb347',\n      // \t\t\t\t\t\twidth: 2\n      // \t\t\t\t\t}\n      // \t\t\t\t};\n      //\n      // \t\t\t\tlet Boredom = {\n      // \t\t\t\t\tx: [],\n      // \t\t\t\t\ty: [],\n      // \t\t\t\t\tmode: \"lines\",\n      // \t\t\t\t\tname: 'Boredom',\n      // \t\t\t\t\tline: {\n      // \t\t\t\t\t\tcolor: '#cfcfc4',\n      // \t\t\t\t\t\twidth: 2\n      // \t\t\t\t\t}\n      // \t\t\t\t};\n      //\n      // \t\t\t\tlet Sadness = {\n      // \t\t\t\t\tx: [],\n      // \t\t\t\t\ty: [],\n      // \t\t\t\t\tmode: \"lines\",\n      // \t\t\t\t\tname: 'Sadness',\n      // \t\t\t\t\tline: {\n      // \t\t\t\t\t\tcolor: '#85A1F2',\n      // \t\t\t\t\t\twidth: 2\n      // \t\t\t\t\t}\n      // \t\t\t\t};\n      //\n      // \t\t\t\tlet Happiness = {\n      // \t\t\t\t\tx: [],\n      // \t\t\t\t\ty: [],\n      // \t\t\t\t\tmode: \"lines\",\n      // \t\t\t\t\tname: 'Happiness',\n      // \t\t\t\t\tline: {\n      // \t\t\t\t\t\tcolor: '#77dd77',\n      // \t\t\t\t\t\twidth: 2\n      // \t\t\t\t\t}\n      // \t\t\t\t};\n      //\n      // \t\t\t\tdata.forEach(function(val) {\n      // \t\t\t\tAnger.x.push(val[\"time\"]);\n      // \t\t\t\tAnger.y.push(val[\"Angry\"]);\n      // \t\t\t\tFear.x.push(val[\"time\"]);\n      // \t\t\t\tFear.y.push(val[\"Fear\"]);\n      // \t\t\t\tExcitement.x.push(val[\"time\"]);\n      // \t\t\t\tExcitement.y.push(val[\"Excited\"]);\n      // \t\t\t\tBoredom.x.push(val[\"time\"]);\n      // \t\t\t\tBoredom.y.push(val[\"Bored\"]);\n      // \t\t\t\tSadness.x.push(val[\"time\"]);\n      // \t\t\t\tSadness.y.push(val[\"Sad\"]);\n      // \t\t\t\tHappiness.x.push(val[\"time\"]);\n      // \t\t\t\tHappiness.y.push(val[\"Happy\"]);\n      // \t\t\t\t});\n      //\n      // \t\t\t\tvar layout2 = {\n      // \t\t\t\tpaper_bgcolor: \"#222831\",\n      // \t\t\t\tplot_bgcolor: \"#222831\",\n      // \t\t\t\ttitle: {\n      // \t\t\t\t\ttext:'  Emotions in Words Spoken',\n      // \t\t\t\t\tfont: {\n      // \t\t\t\t\tfamily: 'Arial, sans-serif',\n      // \t\t\t\t\tsize: 20,\n      // \t\t\t\t\tcolor: '#fdfd96',\n      // \t\t\t\t},\n      // \t\t\t\t\txref: 'paper',\n      // \t\t\t\t\tautomargin: true,\n      // \t\t\t\t\tx: 0.6,\n      // \t\t\t\t\txanchor: 'center',\n      // \t\t\t\t\ty: 0.88,\n      // \t\t\t\t\tyanchor: 'top'\n      // \t\t\t\t},\n      // \t\t\t\tautosize: true,\n      // \t\t\t\t\txaxis: {\n      // \t\t\t\t\t\ttickfont : {\n      // \t\t\t\t\t\t\tsize : 16,\n      // \t\t\t\t\t\t\tcolor : '#fdfd96'\n      // \t\t\t\t\t\t},\n      // \t\t\t\t\t\ttickcolor: '#36454f',\n      // \t\t\t\t\t\ttitle: {\n      // \t\t\t\t\t\t\ttext: 'Time',\n      // \t\t\t\t\t\t\tfont: {\n      // \t\t\t\t\t\t\tfamily: 'Arial, sans-serif',\n      // \t\t\t\t\t\t\tsize: 18,\n      // \t\t\t\t\t\t\tcolor: '#fdfd96',\n      // \t\t\t\t\t\t\t}\n      // \t\t\t\t\t\t},\n      // \t\t\t\t\t},\n      // \t\t\t\t\tyaxis: {\n      // \t\t\t\t\t\tmargin: {\n      // \t\t\t\t\t\t\tautoexpand: true,\n      // \t\t\t\t\t\t},\n      // \t\t\t\t\t\tautomargin: true,\n      // \t\t\t\t\t\ttickfont : {\n      // \t\t\t\t\t\t\tsize : 16,\n      // \t\t\t\t\t\t\tcolor : '#fdfd96'\n      // \t\t\t\t\t\t},\n      // \t\t\t\t\t\ttickcolor: '#fdfd96',\n      // \t\t\t\t\t\ttitle: {\n      // \t\t\t\t\t\ttext: 'Emotions',\n      // \t\t\t\t\t\t\tfont: {\n      // \t\t\t\t\t\t\tfamily: 'Arial, sans-serif',\n      // \t\t\t\t\t\t\tsize: 18,\n      // \t\t\t\t\t\t\tcolor: '#fdfd96'\n      // \t\t\t\t\t\t\t}\n      // \t\t\t\t\t\t}\n      // \t\t\t\t\t}\n      // \t\t\t\t};\n      //\n      // \t\t\t\tvar TEXTEMOTIONChart = document.getElementById('textEmotionChart');\n      // \t\t\t\tPlotly.newPlot(TEXTEMOTIONChart, [Anger, Fear, Excitement, Boredom, Sadness, Happiness], layout2);\n      //\t\t\t}\n    },\n  }, //\n}; //\n</script>\n\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n@import url(\"https://fonts.cdnfonts.com/css/lcd\");\n#textEmotion,\n#faceEmotion,\n#voiceEmotion,\n#wpm {\n  display: inline-block;\n}\ndiv {\n  background-color: none;\n  color: #71c68b;\n}\n.chartWindow {\n  position: relative;\n  display: inline-block;\n  width: 80%;\n}\n.optionsButton {\n  height: 50px;\n  width: 75px;\n  padding: 12px;\n  font-size: 10px;\n  margin: 5px;\n  border: none;\n  font-weight: bold;\n  color: black;\n  font-family: Arial, sans-serif;\n}\n\n.title {\n  color: white;\n}\n\n#messageTwo {\n  color: #f48d79;\n  font-size: 25px;\n}\n\n#feedback {\n  color: #ffea66;\n  font-size: 25px;\n  text-align: left;\n  background-color: #6b206a;\n  padding: 50px;\n  white-space: pre-wrap;\n}\n\n#messageThree {\n  color: white;\n  font-size: 25px;\n}\n\n#begin {\n  background-color: #c300ff;\n  border: none;\n  height: 50px;\n  width: 100px;\n  font-weight: bold;\n  color: black;\n  font-family: Arial, sans-serif;\n  font-size: 20px;\n  margin-top: 40px;\n  margin-bottom: -20px;\n}\n\n#begin:hover {\n  background-color: #fdfd96;\n}\n\n#start {\n  background-color: #cbc3e3;\n  border: none;\n  height: 50px;\n  width: 100px;\n  font-weight: bold;\n  color: black;\n  font-family: Arial, sans-serif;\n  font-size: 20px;\n  margin: 10px;\n}\n\n#start:hover {\n  background-color: lightgreen;\n}\n\n#stop {\n  background-color: #cbc3e3;\n  border: none;\n  height: 50px;\n  width: 100px;\n  font-weight: bold;\n  color: black;\n  font-family: Arial, sans-serif;\n  font-size: 20px;\n  margin: 10px;\n}\n\n#stop:hover {\n  background-color: #ff726f;\n}\n\n#reset {\n  background-color: #cbc3e3;\n  border: none;\n  height: 50px;\n  width: 100px;\n  font-weight: bold;\n  color: black;\n  font-family: Arial, sans-serif;\n  font-size: 20px;\n  margin: 10px;\n}\n\n#reset:hover {\n  background-color: lightyellow;\n}\n\n#pdf {\n  background-color: #c300ff;\n  border: none;\n  height: 50px;\n  width: 100px;\n  font-weight: bold;\n  color: black;\n  font-family: Arial, sans-serif;\n  font-size: 20px;\n  margin: 10px;\n}\n\n#pdf:hover {\n  background-color: #00ffc3;\n}\n\n#next {\n  background-color: #7766c6;\n  border: none;\n  height: 50px;\n  width: 100px;\n  font-weight: bold;\n  color: black;\n  font-family: Arial, sans-serif;\n  font-size: 20px;\n  margin-top: 40px;\n  margin-bottom: -20px;\n}\n\n#next:hover {\n  background-color: #ffc300;\n}\n\n#output {\n  margin: auto;\n  color: #f48d79;\n  background-color: #222831;\n  width: 80%;\n  text-align: left;\n  overflow: auto;\n  height: 170px;\n  font-size: 25px;\n  margin-top: 0px;\n  margin-bottom: 0px;\n}\n\n#wpmChart {\n  overflow: auto;\n  width: 80%;\n  display: inline-block;\n  margin-top: 3px;\n  margin-bottom: 0px;\n}\n\n#readabilityChart {\n  overflow: auto;\n  width: 80%;\n  display: inline-block;\n  margin-top: 3px;\n  margin-bottom: 0px;\n}\n\n#volumeChart {\n  overflow: auto;\n  width: 80%;\n  display: inline-block;\n  margin-top: -3px;\n}\n\n#textEmotionChart {\n  overflow: auto;\n  width: 80%;\n  display: inline-block;\n  margin-top: -3px;\n}\n\n#faceEmotionChart {\n  overflow: auto;\n  width: 80%;\n  display: inline-block;\n  margin-top: -3px;\n}\n\n#rawData {\n  display: none;\n  margin: auto;\n  color: lawngreen;\n  background-color: #222831;\n  width: 80%;\n  text-align: left;\n  overflow: scroll;\n  height: 100px;\n  font-size: 25px;\n  margin: 0px;\n}\n\n#dataHideButton {\n  margin: auto;\n  color: #222831;\n  background-color: #222831;\n  width: 40%;\n  text-align: center;\n  height: 30px;\n  font-size: 10px;\n  margin: 0px;\n  border: none;\n}\n\n#dataShowButton {\n  margin: auto;\n  color: #222831;\n  background-color: #222831;\n  width: 40%;\n  text-align: center;\n  height: 30px;\n  font-size: 10px;\n  margin: 0px;\n  border: none;\n}\n\nh1 {\n  font-size: 50px;\n}\nh3 {\n  margin: 40px 0 0;\n}\nul {\n  list-style-type: none;\n  padding: 0px;\n}\nli {\n  display: inline-block;\n  margin: 0 10px;\n}\na {\n  color: #42b983;\n}\n\n#talking {\n  height: 100px;\n  margin-bottom: -20px;\n  -webkit-filter: invert(1);\n  filter: invert(1);\n}\n\n#timer {\n  background: #222831;\n  color: white;\n  font-size: 50px;\n  font-family: \"LCD\", sans-serif;\n  height: 100px;\n  width: 80%;\n  border: none;\n  font-weight: bold;\n  text-align: center;\n  margin-bottom: 0px;\n}\n\n#timeHolder {\n  background-color: #123b52;\n  color: white;\n  display: none;\n  margin-bottom: 0px;\n}\n\n#speakingTime {\n  background-color: #00ffc3;\n  outline: none;\n  scroll-behavior: smooth;\n  height: 50px;\n  width: 100px;\n  font-weight: bold;\n  color: black;\n  font-family: Arial, sans-serif;\n  font-size: 21px;\n  margin: 10px;\n  text-align: center;\n  border: none;\n}\n\n#speakingTime:hover {\n  background-color: #c300ff;\n}\n\n#volume-visualizer-wrapper {\n  background-color: #222831;\n  margin-top: 0px;\n  padding: 0px;\n  margin-bottom: 0px;\n  width: 80%;\n  display: inline-block;\n  padding-bottom: 10px;\n}\n\n#volume-visualizer {\n  --volume: 0%;\n  position: relative;\n  height: 10px;\n  background-color: #222831;\n  margin-top: 0px;\n  margin-bottom: 0px;\n  width: 100%;\n  border: none;\n  display: inline-block;\n}\n\n#volume-visualizer::before {\n  content: \"\";\n  position: absolute;\n  top: 0;\n  bottom: 0;\n  left: 0;\n  width: var(--volume);\n  background-color: #c300ff;\n  transition: width 100ms linear;\n}\n#container {\n  height: 200px;\n  margin-bottom: 0px;\n  display: none;\n  margin-top: -100px;\n}\n\n.video-container {\n  position: relative;\n  margin-top: 0px;\n  background-color: #222831;\n  width: 80%;\n  display: inline-block;\n}\n\ncanvas {\n  position: absolute;\n  left: 0;\n  top: 0px;\n}\n.result-container {\n  width: 100%;\n  justify-content: center;\n  align-items: center;\n  flex-direction: column;\n}\n.result-container > div {\n  font-size: 1.3rem;\n  padding: 0.5rem;\n  margin: 5px 0;\n  color: white;\n  text-transform: capitalize;\n}\n\nvideo {\n  width: 100%;\n  margin-bottom: -150px;\n  margin-top: 0px;\n}\n\n#loading {\n  height: 50px;\n}\n\n#loadingContainer {\n  color: #fdfd96;\n  margin-bottom: 150%;\n  font-size: 50px;\n}\n\n#specificAndOverallFeedback {\n  color: #ffbf00;\n}\n\n#initialMessage {\n  font-size: 20px;\n  color: #c300ff;\n}\n\n#footer {\n  display: flex;\n  position: float;\n  bottom: 0;\n  margin-top: 27%;\n  height: 3rem;\n  text-align: left;\n}\n\n#bugs {\n  color: white;\n  font-size: 12px;\n}\n\n@page {\n  size: A3 landscape;\n  counter-increment: page;\n  margin: none;\n}\n</style>"]}]}